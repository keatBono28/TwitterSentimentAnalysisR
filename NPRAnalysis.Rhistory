getwd()
getwd()
install.packages("plyr")
install.packages("stringr")
install.packages("base64enc")
install.packages("twitteR")
install.packages("tm")
install.packages("wordcloud")
install.packages("SnowballC")
library(plyr)
library(stringr)
library(base64enc)
library(twitteR)
library(tm)
library(wordcloud)
library(SnowballC)
library(plyr)
library(stringr)
library(base64enc)
library(twitteR)
library(tm)
library(wordcloud)
library(SnowballC)
posWords <- scan('positivewords.txt', what='character', comment.char=';')
negWords <- scan('negativewords.txt', what='character', comment.char=';')
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
scores = laply(sentences, function(sentence, pos.words, neg.words) {
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
sentence = tolower(sentence)
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
setup_twitter_oauth("", "", "", "")
tweetsNPR <- userTimeline("NPR", n=100)
tweetsNPR
dfTweetsNPR <- do.call("rbind", lapply(tweetsNPR, as.data.frame))
scoresNPR <- score.sentiment(dfTweetsNPR$text, posWords, negWords, .progress='text')
write.csv(scores, file ="NPRsentiment.csv")
corpusDataNPR <- Corpus(VectorSource(dfTweetsNPR$text))
corpusDataNPR <- Corpus(VectorSource(str_replace_all(dfTweetsNPR$text,"[^[:graph:]]"," ")))
corpusDataNPR <- tm_map(corpusDataNPR, tolower)
corpusDataNPR <- tm_map(corpusDataNPR, removePunctuation)
corpusDataNPR <- tm_map(corpusDataNPR, removeNumbers)
corpusDataNPR <- tm_map(corpusDataNPR, removeWords, stopwords("english"))
corpusDataNPR <- tm_map(corpusDataNPR, stemDocument)
corpusDataNPR <- tm_map(corpusDataNPR, stripWhitespace)
tdmDataNPR <- TermDocumentMatrix(corpusDataNPR)
mDataNPR <- as.matrix(tdmDataNPR)
freqOfTermsNPR <- sort(rowSums(mDataNPR), decreasing=TRUE)
namesFromDataNPR <- names(freqOfTermsNPR)
dfDataNPR <- data.frame(word=namesFromDataNPR, freq=freqOfTermsNPR)
dfTweetsNPR <- do.call("rbind", lapply(tweetsNPR, as.data.frame))
scoresNPR <- score.sentiment(dfTweetsNPR$text, posWords, negWords, .progress='text')
write.csv(scoresNPR, file ="NPRsentiment.csv")
corpusDataNPR <- Corpus(VectorSource(dfTweetsNPR$text))
corpusDataNPR <- Corpus(VectorSource(str_replace_all(dfTweetsNPR$text,"[^[:graph:]]"," ")))
corpusDataNPR <- tm_map(corpusDataNPR, tolower)
corpusDataNPR <- tm_map(corpusDataNPR, removePunctuation)
corpusDataNPR <- tm_map(corpusDataNPR, removeNumbers)
corpusDataNPR <- tm_map(corpusDataNPR, removeWords, stopwords("english"))
corpusDataNPR <- tm_map(corpusDataNPR, stemDocument)
corpusDataNPR <- tm_map(corpusDataNPR, stripWhitespace)
tdmDataNPR <- TermDocumentMatrix(corpusDataNPR)
mDataNPR <- as.matrix(tdmDataNPR)
freqOfTermsNPR <- sort(rowSums(mDataNPR), decreasing=TRUE)
namesFromDataNPR <- names(freqOfTermsNPR)
dfDataNPR <- data.frame(word=namesFromDataNPR, freq=freqOfTermsNPR)
wordcloud(dfDataNPR$word, dfDataNPR$freq, min.freq=3)
wordcloud(dfDataNPR$word, dfDataNPR$freq, min.freq=8)
tweetsFoxNews <- userTimeline("FoxNews", n=100)
dfTweetsFoxNews <- do.call("rbind", lapply(tweetsFoxNews, as.data.frame))
scoresFoxNews <- score.sentiment(dfTweetsFoxNews$text, posWords, negWords, .progress='text')
write.csv(scoresFoxNews, file ="FoxNewssentiment.csv")
corpusDataFoxNews <- Corpus(VectorSource(dfTweetsFoxNews$text))
corpusDataFoxNews <- Corpus(VectorSource(str_replace_all(dfTweetsFoxNews$text,"[^[:graph:]]"," ")))
corpusDataFoxNews<- tm_map(corpusDataFoxNews, tolower)
corpusDataFoxNews <- tm_map(corpusDataFoxNews, removePunctuation)
corpusDataFoxNews <- tm_map(corpusDataFoxNews, removeNumbers)
corpusDataFoxNews <- tm_map(corpusDataFoxNews, removeWords, stopwords("english"))
corpusDataFoxNews <- tm_map(corpusDataFoxNews, stemDocument)
corpusDataFoxNews <- tm_map(corpusDataFoxNews, stripWhitespace)
tdmDataFoxNews <- TermDocumentMatrix(corpusDataFoxNews)
mDataFoxNews <- as.matrix(tdmDataFoxNews)
freqOfTermsFoxNews <- sort(rowSums(mDataFoxNews), decreasing=TRUE)
namesFromDataFoxNews <- names(freqOfTermsFoxNews)
dfDataFoxNews <- data.frame(word=namesFromDataFoxNews, freq=freqOfTermsFoxNews)
wordcloud(dfDataFoxNews$word, dfDataFoxNews$freq, min.freq=3)
wordcloud(dfDataFoxNews$word, dfDataFoxNews$freq, min.freq=8)
tweetsNEWS <- c(tweetsNPR, tweetsFoxNews)
tweetsNEWS
dfTweetsNEWS <- do.call("rbind", lapply(tweetsNEWS, as.data.frame))
scoresNEWS <- score.sentiment(dfTweetsNEWS$text, posWords, negWords, .progress='text')
write.csv(scoresNEWS, file ="NEWSsentiment.csv")
corpusDataNEWS <- Corpus(VectorSource(dfTweetsNEWSs$text))
corpusDataNEWS <- Corpus(VectorSource(str_replace_all(dfTweetsNEWS$text,"[^[:graph:]]"," ")))
corpusDataNEWS <- tm_map(corpusDataNEWS, tolower)
corpusDataNEWS <- tm_map(corpusDataNEWS, removePunctuation)
corpusDataNEWS <- tm_map(corpusDataNEWS, removeNumbers)
corpusDataNEWS <- tm_map(corpusDataNEWS, removeWords, stopwords("english"))
corpusDataNEWS <- tm_map(corpusDataNEWS, stemDocument)
corpusDataNEWS <- tm_map(corpusDataNEWS, stripWhitespace)
tdmDataNEWS <- TermDocumentMatrix(corpusDataNEWS)
mDataNEWS <- as.matrix(tdmDataNEWS)
freqOfTermsNEWS <- sort(rowSums(mDataNEWS), decreasing=TRUE)
namesFromDataNEWS <- names(freqOfTermsNEWS)
dfDataNEWS <- data.frame(word=namesFromDataNEWS, freq=freqOfTermsNEWS)
dfTweetsNEWS <- do.call("rbind", lapply(tweetsNEWS, as.data.frame))
scoresNEWS <- score.sentiment(dfTweetsNEWS$text, posWords, negWords, .progress='text')
write.csv(scoresNEWS, file ="NEWSsentiment.csv")
corpusDataNEWS <- Corpus(VectorSource(dfTweetsNEWS$text))
corpusDataNEWS <- Corpus(VectorSource(str_replace_all(dfTweetsNEWS$text,"[^[:graph:]]"," ")))
corpusDataNEWS <- tm_map(corpusDataNEWS, tolower)
corpusDataNEWS <- tm_map(corpusDataNEWS, removePunctuation)
corpusDataNEWS <- tm_map(corpusDataNEWS, removeNumbers)
corpusDataNEWS <- tm_map(corpusDataNEWS, removeWords, stopwords("english"))
corpusDataNEWS <- tm_map(corpusDataNEWS, stemDocument)
corpusDataNEWS <- tm_map(corpusDataNEWS, stripWhitespace)
tdmDataNEWS <- TermDocumentMatrix(corpusDataNEWS)
mDataNEWS <- as.matrix(tdmDataNEWS)
freqOfTermsNEWS <- sort(rowSums(mDataNEWS), decreasing=TRUE)
namesFromDataNEWS <- names(freqOfTermsNEWS)
dfDataNEWS <- data.frame(word=namesFromDataNEWS, freq=freqOfTermsNEWS)
wordcloud(dfDataNEWS$word, dfDataNEWS$freq, min.freq=3)
wordcloud(dfDataNEWS$word, dfDataNEWS$freq, min.freq=8)
wordcloud(dfDataNEWS$word, dfDataNEWS$freq, min.freq=15)
q()
